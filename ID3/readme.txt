原始香农熵，只考虑最终分类下，各种分类的概率造成的结果，然后计算香农熵。
实际上，造成结果的原因是更细致的，或者说，我们想去探究更多的因素造成的结果时，扩充
香农熵的计算方式，就显得有必要。

calcShannonEnt()函数：
	默认-1列为分类结果，此步的操作直接按照-1列的类别划分，直接按照结果划分计算香农熵。
	属于最原始粗糙的香农熵计算。实际上也是属于基础螺丝函数，后面划分后的数据依然要不断调用此。
	作用：面对各种情况，直接按照最终结果进行计算。基石

splitDataSet(dataSet, axis, value)函数：
	选取dataSet中的axis列（次维）元素，其中符合value值的，按照最高维度方向，得到去掉该value值的
	newDataSet。
	就是newDataSet,满足两个条件，去掉axis列，然后保留axis值等于value的行。
	作用：比对不同划分香农熵的基础计算函数
	
chooseBestFeatureToSplit(dataSet)函数:
	初始化最优香农熵的值（0），初始化最佳列（-1）
	
	作用：得到最好的第一步用于划分的列（香农熵最大），即i值（0~倒数第二列）。

majorityCnt(classList):
	
	作用：选取此列中，数量最多的分类，并返回它，实际上是防止数据噪点。
	当只剩下一列数据的时候（分类被全部消耗），分类却依然有2个，那只能认为更多的那个才是真正的分类。

createTree(dataSet, labels)函数：
	输入数据集，和类别信息，其中数据集会比类别信息多一列，存储分类结果。
	labels属于可被消耗资源。
	存在两种情况，可以停止这个函数的递归调用：
	①是，当分类结果全部一致，则停止，返回分类结果；
	②是，当只剩下最后一列信息，返回分类数量更多的那种分类。
	
	然后消耗掉那一列，继续递归调用此函数。最终会得到mTree

classify(inputTree, featLabels, testVec):
	遍历树的节点，如果满足，则停止。
	作用：给testVec分类。
	